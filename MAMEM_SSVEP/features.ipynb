{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentação e criação do vetor de características\n",
    "\n",
    "**Observação inicial**: para os trabalhos posteriores, será levado em consideração que os dados estão corretos e filtrados conforme na aula de \"Pré-processamento\". Portando, antes de iniciar este conteúdo, vocês terão que ter concluído as questões passadas e como **tarefa** salvar um arquivo com dados filtrados (não executar todo `preprocessing.ipynb`).\n",
    "\n",
    "Serão utilizados nesta aula os dados sem nenhuma filtragem e com o conjunto de canais escolhidos aleatoriamente.\n",
    "\n",
    "## Introdução\n",
    "\n",
    "Um formato importante do *dataset* para a classificação dos dados, é estar organizado preferencialmente em duas dimensões. As linhas serão as amostras (rotuladas ou não) e as colunas, as características. Além disso, os dados para cada uma das características deve fazer algum sentido para a boa atuação do classificador. Para essa matriz final, damos o nome de `vetor de características`.\n",
    "\n",
    "Em experimentos SSVEP-BCI, a característica mais forte é o `PSD` (*Power Spectral Density*). O `PSD`, como o nome sugere, é obtido por meio do sinal no domínio da frequência, aplicando a seguinte fórmula: $|x_i|^2$. O `PSD` potencializa a energia das frequências mais evidentes, melhorando o desempenho de classificação.\n",
    "\n",
    "Alguns métodos da biblioteca MNE nos dão um vetor de características pronto. Porém, é interessante realizarmos algumas etapas passo a passo sem o uso inicial da biblioteca para entendermos o funcionamento do método e alterar como quisermos.\n",
    "\n",
    "\n",
    "## Transformação de domínio (e segmentação)\n",
    "\n",
    "O `shape` inicial dos dados é: `(125, 256, 1205) -> (trials, channels, data)`. Vamos aplicar a Transformada Rápida de Fourier em Tempo Curto (STFT) (após carregar e filtrar os dados):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import mne\n",
    "from scipy.signal import stft\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files/ssvep-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    4816.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "125 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "<EpochsFIF  |   125 events (all good), 0 - 4.816 sec, baseline off, ~15.1 MB, data loaded,\n",
      " '1': 25\n",
      " '2': 25\n",
      " '3': 30\n",
      " '4': 25\n",
      " '5': 20>\n"
     ]
    }
   ],
   "source": [
    "# carregamento do dataset (FIF file)\n",
    "epochs = mne.read_epochs('files/ssvep-epo.fif')\n",
    "# filtranndo apenas alguns canais\n",
    "epochs.pick_channels(['E108', 'E109', 'E116', 'E125', 'E118', 'E117', 'E126',\n",
    "                      'E139', 'E127', 'E138', 'E140', 'E150', 'E151'])\n",
    "print(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 13, 1205)\n",
      "Effective window size : 1.024 (s)\n",
      "[[[0.93674441 0.74141311 0.38201137 ... 0.68028774 0.5873291  0.2476712 ]\n",
      "  [0.97638268 0.63740008 0.2965196  ... 0.64086363 0.59099704 0.23757344]\n",
      "  [1.03881271 0.74823094 0.35052467 ... 0.76193674 0.66034644 0.25821164]\n",
      "  ...\n",
      "  [0.75223499 0.69451247 0.32560598 ... 0.57718996 0.40823829 0.07124297]\n",
      "  [0.98549479 0.94989159 0.41630772 ... 0.65147623 0.47961005 0.1042054 ]\n",
      "  [0.98260192 0.92993171 0.41861242 ... 0.61724877 0.46385364 0.0900444 ]]\n",
      "\n",
      " [[0.38381504 0.71549564 0.34765654 ... 0.22972511 0.45814206 0.59436434]\n",
      "  [0.53593299 0.67116295 0.27774932 ... 0.13494958 0.324484   0.39715296]\n",
      "  [0.55843889 0.7548622  0.30406947 ... 0.20261892 0.46116079 0.56648374]\n",
      "  ...\n",
      "  [0.51577375 0.45455115 0.18185857 ... 0.11417187 0.27062902 0.39060153]\n",
      "  [0.46213031 0.5655062  0.35507217 ... 0.17301737 0.29036647 0.50118811]\n",
      "  [0.42661521 0.51815579 0.24817847 ... 0.14329983 0.29927486 0.46798453]]\n",
      "\n",
      " [[0.84469972 0.73678515 0.65497281 ... 0.34986332 0.88886546 0.52453442]\n",
      "  [0.87411108 0.86245069 0.51877943 ... 0.18682573 0.65741933 0.38254332]\n",
      "  [0.91390991 0.86062721 0.63587545 ... 0.30298754 0.93277657 0.51513614]\n",
      "  ...\n",
      "  [0.52918706 0.63982467 0.55696052 ... 0.13063089 0.4648692  0.26732199]\n",
      "  [0.7738352  0.76526243 0.6440064  ... 0.26967144 0.76644904 0.44505526]\n",
      "  [0.55084927 0.70537328 0.62557339 ... 0.2229104  0.63161029 0.3586787 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.83995382 0.67909845 1.00762685 ... 0.3092533  0.55256607 0.86061235]\n",
      "  [0.53567081 0.42139135 0.7745987  ... 0.27107412 0.44418105 0.69002322]\n",
      "  [0.85673446 0.70438645 1.10090566 ... 0.30535355 0.55460465 0.89296829]\n",
      "  ...\n",
      "  [0.47545397 0.33212007 0.42305442 ... 0.36059668 0.59691362 0.88003398]\n",
      "  [0.85774297 0.61336533 0.68976328 ... 0.39934679 0.53364597 0.8973827 ]\n",
      "  [0.69624141 0.4462031  0.48167206 ... 0.37142817 0.61390155 0.91162226]]\n",
      "\n",
      " [[1.02183845 0.32836085 0.55073433 ... 0.36002161 0.38402601 0.37839722]\n",
      "  [0.72837099 0.27738274 0.41673908 ... 0.31857238 0.36913386 0.31524619]\n",
      "  [0.90788517 0.34026491 0.59331452 ... 0.38230948 0.43248138 0.4159616 ]\n",
      "  ...\n",
      "  [0.52622599 0.24215553 0.30928347 ... 0.48057041 0.31508509 0.21513476]\n",
      "  [0.88837016 0.33637954 0.56331548 ... 0.53971664 0.41211846 0.32847387]\n",
      "  [0.70409267 0.29466216 0.42856972 ... 0.40176798 0.32026051 0.29912957]]\n",
      "\n",
      " [[1.65571795 1.66360452 0.97683472 ... 0.37201179 0.14250441 0.432256  ]\n",
      "  [1.32264683 1.25313723 0.64589776 ... 0.36024397 0.12358975 0.31779358]\n",
      "  [1.635285   1.63701252 0.96655    ... 0.46679292 0.16365806 0.41173463]\n",
      "  ...\n",
      "  [1.29690716 0.96729681 0.42676288 ... 0.30176463 0.09248173 0.21993999]\n",
      "  [1.86635698 1.48471761 0.66926194 ... 0.30603984 0.08026096 0.2822725 ]\n",
      "  [1.55715753 1.23590223 0.56612543 ... 0.29608366 0.07124195 0.20715412]]]\n",
      "(125, 13, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "# extraindo somente os dados do objeto MNE\n",
    "data = epochs.get_data()\n",
    "print(data.shape) # domínio do tempo\n",
    "\n",
    "epochs_welch, freqs = mne.time_frequency.psd_welch(epochs, fmin = 4, fmax = 15) \n",
    "print(epochs_welch)\n",
    "\n",
    "# aplicando STFT\n",
    "_, _, w = stft(epochs_welch, fs=241, nperseg=11, noverlap=6)\n",
    "# w = np.swapaxes(w, 3, 4)\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obemos um `shape` diferente, acrescentando uma dimensão a mais em nossos dados. Isso é devido a quantidade de janelas ou segmentos informados (`nperseg`) e a sobreposição utilizada (`overlap`). **DISCUSSÃO EM AULA**\n",
    "\n",
    "Aplicando o `PSD` teremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 13, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "W = np.abs(w) ** 2\n",
    "\n",
    "Wabs=np.abs(w)\n",
    "\n",
    "# w = np.reshape(w, (125, 13, 17 * 77)) # <= questão de projeto\n",
    "# w = w.transpose(0, 2, 1)\n",
    "# w = np.reshape(w, (125 * 1309, 13))\n",
    "print(W.shape)\n",
    "\n",
    "# shape resultante: (125, 13, 17, 77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração de características\n",
    "\n",
    "Não é uma boa estratégia utilizar os dados \"crus\" de `PSD` para a classificação. Desta forma, vamos adotar alguns algoritmos simples para reduzir uma dimensão dos dados e potencializar nossas características. Uma lista de característica é listada [por este artigo intitulado \"*A wearable wireless brain-computer interface using steady-state visual evoked potentials*\"](https://www.researchgate.net/publication/334854837_A_wearable_wireless_brain-computer_interface_using_steady-state_visual_evoked_potentials). Já que temos o PSD dos dados, vamos demonstrar a aplicação do \"*Mean of PSD*\" ou `FMN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMN: (125, 13, 6)\n",
      "RSS: (125, 13, 6)\n",
      "max: (125, 13, 6)\n",
      "min: (125, 13, 6)\n",
      "mean:  (125, 13, 6)\n",
      "std:  (125, 13, 6)\n",
      "Kurtosis:  (125, 13, 6)\n",
      "RMS:  (125, 13, 6)\n",
      "avm:  (125, 13, 6)\n",
      "mad:  (125, 13, 6)\n",
      "mag:  (125, 13, 6)\n",
      "stdpsd:  (125, 13, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import kurtosis, skew, median_abs_deviation\n",
    "from scipy.fft import fft\n",
    "from sklearn import metrics\n",
    "\n",
    "fmn = np.mean(W, axis=-1)\n",
    "print('FMN:', fmn.shape)\n",
    "\n",
    "# Root of sum of squares\n",
    "rss = np.sqrt(np.sum(W, axis=-1))\n",
    "print('RSS:', rss.shape)\n",
    "\n",
    "maxvalue = np.max(w, axis=-1)\n",
    "print ('max:', maxvalue.shape)\n",
    "\n",
    "minvalue = np.min(w, axis=-1)\n",
    "print ('min:', maxvalue.shape)\n",
    "\n",
    "mean = np.mean(w, axis=-1)\n",
    "print (\"mean: \", mean.shape)\n",
    "\n",
    "std = np.std(w, axis=-1)\n",
    "print (\"std: \", std.shape)\n",
    "\n",
    "kurt = kurtosis(w, axis=-1)\n",
    "print (\"Kurtosis: \", kurt.shape)\n",
    "\n",
    "#skewn = skew(w, axis=-1)\n",
    "#print (\"Skewness: \", skewn.shape)\n",
    "\n",
    "rms = np.sqrt(np.mean(w**2, axis=-1))\n",
    "print (\"RMS: \", rms.shape)\n",
    "\n",
    "# auc = metrics.auc(w)\n",
    "# print (\"auc: \", auc.shape)\n",
    "\n",
    "avm = np.mean(Wabs, axis=-1)\n",
    "print(\"avm: \", avm.shape)\n",
    "\n",
    "mad = median_abs_deviation(w, axis=-1)\n",
    "print(\"mad: \", mad.shape)\n",
    "\n",
    "mag = np.linalg.norm(w, axis=-1)\n",
    "print(\"mag: \", mag.shape)\n",
    "\n",
    "stdpsd = np.std(w, axis=-1)\n",
    "print (\"stdpsd: \", stdpsd.shape)\n",
    "\n",
    "#fft = fft(w, axis=-1)\n",
    "#print(\"fft: \", fft.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a aplicação de algumas características, juntamos todas elas no mesmo conjunto de dados e transformamos cada eletrodo em uma característica. Em outras palavras, o *shape* final que ficou no seguinte formato:`(125, 13, 17)`. Agora deverá ficar `(125 * 17, 13) => (2125, 13)`.\n",
    "\n",
    "Se mais características fossem adicionadas, elas entrariam como multiplicação nas colunas. No exemplo anterior temos apenas uma característica desenvolvida. Se adicionarmos 4 características, o `shape` do vetor de características ficaria no seguinte formato: `(2125, 13 * 4) => (2125, 52)`. Explicando os dados, seriam 2125 amostras e 52 características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos dados: (750, 156)\n"
     ]
    }
   ],
   "source": [
    "# realização das transformações finais (TAREFA)\n",
    "\n",
    "# finalizando o exemplo com a junção das duas características criadas\n",
    "features = list()\n",
    "for feature in (fmn, rss, mean, maxvalue, minvalue, std, kurt, rms, avm, mad, mag, stdpsd):\n",
    "    feature = feature.transpose(0, 2, 1)\n",
    "    feature = feature.reshape(feature.shape[0] * feature.shape[1],\n",
    "                              feature.shape[2])\n",
    "    features.append(feature)\n",
    "\n",
    "# vetor de características final\n",
    "X = np.concatenate(features, axis=-1)\n",
    "print('Shape dos dados:', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptação do vetor de *labels*\n",
    "\n",
    "Temos que adaptar o vetor de *labels* para ficar do mesmo tamanho (mesma quantidade de linhas) que o vetor de dados `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape original dos labels (125,)\n",
      "Shape final dos labels (750,)\n"
     ]
    }
   ],
   "source": [
    "y = np.load('files/labels.npy')\n",
    "print('Shape original dos labels', y.shape)\n",
    "\n",
    "size = int(X.shape[0] / y.shape[0])\n",
    "y = np.concatenate([y for i in range(size)])\n",
    "print('Shape final dos labels', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questões de projeto\n",
    "\n",
    "1) Nem sempre os canais são vistos como características. Uma outra forma é adicionar os canais às amostras (reduzindo a quantidade de características e aumentando a quantidade de amostras). O resultado disso deve ser avaliado.\n",
    "\n",
    "2) É comum a aplicação de algum algoritmo para reduzir todos os canais ou transformar apenas em um (que é o caso de aplicar a média de todos os eletrodos/canais).\n",
    "\n",
    "3) Adicionar características ruins confundem o resultado? Características que não estão relacionadas ao domínio do problema pode ser ruim? Isso deve ser avaliado..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respostas \n",
    "1) Avaliado.\n",
    "\n",
    "2) Sim, como demonstrado acima, foi adicionado todos os vetores de características em uma lista única, referente as extrações da região que está sendo analisada. Essa técnica é utilizada para reduzir e simplificar a análise do classificador.\n",
    "\n",
    "3) Sim, pois como no experimento, estamos analisando a região parietal, para-occiptal, occipital, referente a visão do indivíduo. Caso for aplicado um cálculo de média em regiões que não processam informações da visão, como o lobo-frontal que é responsável pelas ações e movimentos, seria considerado como um ruído nos resultados do experimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
